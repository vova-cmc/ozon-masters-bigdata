{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow tracking\n",
    "### The MLflow Tracking component is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's log some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_param(\"param1\", \"This is a param\")\n",
    "mlflow.log_metric(\"ROC AUC\", 0.75)\n",
    "mlflow.log_metric(\"ROC AUC\", 0.8)\n",
    "mlflow.log_metric(\"ROC AUC\", 0.88)\n",
    "with open(\"artifact.txt\", mode=\"w\") as f:\n",
    "    f.write(\"This is an artifact file\")\n",
    "mlflow.log_artifact(\"artifact.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can start a development MLflow UI server using `mlflow ui` shell command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Tracking is organized around the concept of *runs*, which are executions of some piece of data science code. Each run records the following information:\n",
    "* Code Version\n",
    "* Start & End Time\n",
    "* Source\n",
    "* Parameters\n",
    "* Metrics\n",
    "* Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Run* is started automatically as soon as you start logging stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_param(\"param2\", \"This is in the same run as param1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You have to explicitly end current run or use a context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a8778c2310454cbd80eb0b438e7e9914'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-75fba35b8951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"ROC AUC\": 0.7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can group multiple runs as an *experiment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow.create_experiment(\"My first experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    mlflow.log_param(\"param\", \"param-pam-pam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you don't set experiment id, it will fall back to \"Default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"PR AUC\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also name your runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"Run with default hyperparameters\"):\n",
    "    mlflow.log_param(\"alpha\", 0.01)\n",
    "    mlflow.log_metric(\"PR AUC\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can communicate with MLflow server via `MlflowClient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlflow.tracking.client.MlflowClient at 0x7efdb888bd90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = client.get_experiment_by_name(\"My first experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/users/vova-cmc/ozon-masters-bigdata/lectures/lect8%20-%20MlFlow/mlruns/1', experiment_id='1', lifecycle_stage='active', name='My first experiment', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Run: data=<RunData: metrics={'PR AUC': 1.0}, params={'alpha': '0.01'}, tags={'mlflow.runName': 'Run with default hyperparameters',\n",
       "  'mlflow.source.name': '/opt/conda/envs/dsenv/lib/python3.7/site-packages/ipykernel_launcher.py',\n",
       "  'mlflow.source.type': 'LOCAL',\n",
       "  'mlflow.user': 'vova-cmc'}>, info=<RunInfo: artifact_uri='file:///home/users/vova-cmc/ozon-masters-bigdata/lectures/lect8%20-%20MlFlow/mlruns/1/41f48d5cffef4a44bbcdd249354fd939/artifacts', end_time=1620288486216, experiment_id='1', lifecycle_stage='active', run_id='41f48d5cffef4a44bbcdd249354fd939', run_uuid='41f48d5cffef4a44bbcdd249354fd939', start_time=1620288486206, status='FINISHED', user_id='vova-cmc'>>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_runs(experiment_ids=experiment.experiment_id, filter_string=\"metrics.`PR AUC` > 0.9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [More on search syntax](https://www.mlflow.org/docs/latest/search-syntax.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow tracking server has two major components:\n",
    "* backend store\n",
    "* artifact store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The backend store is where MLflow Tracking Server stores experiment and run metadata as well as params, metrics, and tags for runs. It is either file store or SQLAlchemy compatible database. By default the backend is file based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6f308dd1ac944358a07f942e4ea09a82  cb80e95af7e446ffa2e672138d094e75\r\n",
      "a8778c2310454cbd80eb0b438e7e9914  meta.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/$EXPERIMENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = client.search_runs(experiment_ids=EXPERIMENT_ID)[-1].info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts  meta.yaml  metrics  params  tags\r\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/$EXPERIMENT_ID/$RUN_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The artifact store is a location suitable for large data (such as an S3 bucket or shared NFS file system) and is where clients log their artifact output (for example, models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/$EXPERIMENT_ID/$RUN_ID/artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_uri: file:///home/users/vova-cmc/ozon-masters-bigdata/lectures/lect8%20-%20MlFlow/mlruns/0/a8778c2310454cbd80eb0b438e7e9914/artifacts\r\n",
      "end_time: 1620288215007\r\n",
      "entry_point_name: ''\r\n",
      "experiment_id: '0'\r\n",
      "lifecycle_stage: active\r\n",
      "name: ''\r\n",
      "run_id: a8778c2310454cbd80eb0b438e7e9914\r\n",
      "run_uuid: a8778c2310454cbd80eb0b438e7e9914\r\n",
      "source_name: ''\r\n",
      "source_type: 4\r\n",
      "source_version: ''\r\n",
      "start_time: 1620287704818\r\n",
      "status: 3\r\n",
      "tags: []\r\n",
      "user_id: vova-cmc\r\n"
     ]
    }
   ],
   "source": [
    "!cat mlruns/$EXPERIMENT_ID/$RUN_ID/meta.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A separate artifact store is super useful for data scientists to share large datasets, so these datasets don't need to be rebuild from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow models\n",
    "### An MLflow Model is a standard format for packaging machine learning models that can be used in a variety of downstream tools—for example, real-time serving through a REST API or batch inference on Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(*make_classification())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.sklearn.log_model(estimator, artifact_path=\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `log_model` saves trained model in a special format, but don't track model hyperparameters. How can this be resolved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    estimator = RandomForestClassifier()\n",
    "    mlflow.log_params(estimator.get_params())\n",
    "    estimator.fit(X_train, y_train)\n",
    "    accuracy = estimator.score(X_test, y_test)\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    mlflow.sklearn.log_model(estimator, artifact_path=\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some model flavors implement [automatic logging](https://www.mlflow.org/docs/latest/tracking.html#automatic-logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "num_round = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(data=X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgboost.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:25:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    bst = xgboost.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics are automatically logged if early stopping is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param[\"eval_metric\"] = \"auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.79779\n",
      "[1]\teval-auc:0.81250\n",
      "[2]\teval-auc:0.84559\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    bst = xgboost.train(param, dtrain, num_round, evals=[(dtest, 'eval')], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This becomes especially handy for tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0b00743bbfe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.5-py2.py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/jupyterhub-env/lib/python3.6/site-packages (from hyperopt) (1.15.0)\n",
      "Collecting networkx>=2.2\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /opt/jupyterhub-env/lib/python3.6/site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 16.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 75 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 3.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=1601a584aead119c7fc56ffd0331ae2cff3101a2e7fd273525436d530ab6e486\n",
      "  Stored in directory: /home/users/vova-cmc/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "Successfully built future\n",
      "Installing collected packages: numpy, tqdm, scipy, networkx, future, cloudpickle, hyperopt\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/opt/jupyterhub-env/lib/python3.6/site-packages/numpy'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/jupyterhub-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'XGboost hyperparameters' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"XGboost hyperparameters\")\n",
    "mlflow.xgboost.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    with mlflow.start_run():\n",
    "        num_round = int(params.pop(\"n_estimators\"))\n",
    "        watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "        gbm_model = xgboost.train(params, dtrain, num_round, evals=watchlist, verbose_eval=True)\n",
    "        predictions = gbm_model.predict(dtest,\n",
    "                                        ntree_limit=gbm_model.best_iteration + 1)\n",
    "        score = roc_auc_score(y_test, predictions)\n",
    "        loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(random_state=5757):\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 10, 20, 1),\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        'eval_metric': 'auc',\n",
    "        'objective': 'binary:logistic',\n",
    "        'seed': random_state\n",
    "    }\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, max_evals=5)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-b755b4f32c7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-2e1f1da2fa01>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(random_state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5757\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     space = {\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m'eta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK let's return to model logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = client.get_experiment_by_name(\"XGboost hyperparameters\").experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-b25e0d434bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRUN_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXPERIMENT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attribute.start_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "RUN_ID = client.search_runs(EXPERIMENT_ID, order_by=[\"attribute.start_time\"])[-1].info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a8778c2310454cbd80eb0b438e7e9914'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: mlruns/2/a8778c2310454cbd80eb0b438e7e9914/artifacts/model/MLmodel: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat mlruns/$EXPERIMENT_ID/$RUN_ID/artifacts/model/MLmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: mlruns/2/a8778c2310454cbd80eb0b438e7e9914/artifacts/model/conda.yaml: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat mlruns/$EXPERIMENT_ID/$RUN_ID/artifacts/model/conda.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Flavors* are the key concept that makes MLflow Models powerful: they are a convention that deployment tools can use to understand the model, which makes it possible to write tools that work with models from any ML library without having to integrate each tool with each library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymodel = mlflow.pyfunc.load_model(f\"mlruns/{EXPERIMENT_ID}/{RUN_ID}/artifacts/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.PyFuncModel"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.97011787e-01, -4.37778410e-01, -9.90481805e-01,\n",
       "         6.35516781e-01, -6.50844600e-01,  2.89035649e-01,\n",
       "         2.94370350e-01,  7.46032090e-01, -3.13528302e+00,\n",
       "        -1.92101562e+00,  2.18396340e-01, -3.06256217e-01,\n",
       "         2.00263161e+00, -2.89424733e+00,  1.59550142e-01,\n",
       "        -9.83212996e-01, -5.43435411e-01, -1.83512075e+00,\n",
       "        -9.72914428e-01,  1.43375706e-01],\n",
       "       [ 4.84418406e-01,  6.59529717e-01,  1.71458779e+00,\n",
       "         1.69649287e+00, -3.24274390e-01,  1.79945298e-01,\n",
       "        -3.35645787e-01,  2.38402533e-01, -1.78089070e+00,\n",
       "        -1.38335437e+00,  1.47016258e+00,  8.13139988e-01,\n",
       "        -7.62926286e-01, -1.49500396e+00, -4.86484747e-01,\n",
       "        -1.07540269e+00, -2.02313826e+00, -8.31772732e-01,\n",
       "         4.20055411e-01, -6.03500912e-01],\n",
       "       [-7.10188645e-01,  6.34483126e-01,  1.55347620e+00,\n",
       "        -8.51243987e-01,  1.87924811e+00,  3.29910554e-01,\n",
       "        -5.31020943e-01,  1.74786445e-01, -1.42550691e+00,\n",
       "        -8.13951026e-01, -7.65019236e-01, -1.03924315e+00,\n",
       "         1.29733349e+00, -5.42458526e-01,  2.73430703e-01,\n",
       "        -7.09179311e-01,  1.01867078e-01, -1.41635054e+00,\n",
       "         7.85983309e-01, -3.62347754e-02],\n",
       "       [ 1.48630258e+00, -4.57088711e-01,  1.21337396e-02,\n",
       "         4.59103170e-01,  1.70063930e+00, -8.52598390e-01,\n",
       "         7.24641100e-01,  1.71175300e+00, -2.43201274e-01,\n",
       "        -1.59961039e-01, -1.74964746e+00,  2.78160751e-01,\n",
       "         8.41245115e-02, -1.39765420e+00,  8.43746354e-01,\n",
       "         1.05443887e+00, -1.06401772e-01, -4.92812846e-02,\n",
       "        -6.18338448e-01,  1.54848412e+00],\n",
       "       [-5.45661686e-02,  6.98573554e-01,  4.09864016e-01,\n",
       "         3.60936271e-01, -5.13863962e-01,  2.31788673e-02,\n",
       "         6.76400254e-01, -7.43179945e-01,  3.80503996e-01,\n",
       "         6.44782455e-02, -3.00918128e-01,  1.41166293e+00,\n",
       "        -1.34004737e+00, -6.51086205e-01,  7.65016892e-01,\n",
       "         1.22418257e+00, -9.23689519e-01,  9.76582813e-02,\n",
       "         2.11093334e+00,  7.13774995e-01],\n",
       "       [ 9.26725049e-01, -1.36492338e+00, -1.09671981e+00,\n",
       "         2.71125074e+00,  8.94671123e-01,  6.83677543e-01,\n",
       "        -1.23770976e+00, -7.99438452e-01,  9.87801250e-01,\n",
       "         6.98834073e-01, -4.33631041e-01, -4.44697958e-01,\n",
       "        -2.21549864e-02,  7.29317893e-01,  6.44211185e-01,\n",
       "        -9.54161849e-01,  7.20426304e-01,  7.77669167e-01,\n",
       "        -6.43058607e-01,  1.07792376e+00],\n",
       "       [-6.86770376e-02,  6.00467080e-01,  9.39345242e-02,\n",
       "        -2.22160490e+00, -1.15592635e+00, -6.70581827e-01,\n",
       "         1.58258836e+00,  1.04281538e+00, -8.08698252e-01,\n",
       "        -5.17273483e-01,  6.38267065e-01, -2.45961410e-02,\n",
       "         3.74905932e-01, -2.03228995e-01, -5.65385401e-01,\n",
       "         1.50064677e+00, -2.67950750e-01, -4.09089714e-01,\n",
       "        -4.12006406e-01, -7.95549123e-01],\n",
       "       [ 6.17469228e-02,  4.52811951e-01,  3.30829807e-01,\n",
       "         8.77253431e-01, -2.01715313e+00,  1.77193076e-01,\n",
       "        -1.43387123e-01, -1.92492962e+00, -2.01295571e+00,\n",
       "        -1.16369321e+00, -3.55652027e-01,  6.99995887e-01,\n",
       "         1.73885764e+00, -3.42204293e-01, -2.13974644e-01,\n",
       "        -1.24504088e+00,  5.98537246e-02, -1.00456262e-01,\n",
       "         1.88338522e+00,  7.30626504e-01],\n",
       "       [ 8.78594754e-01,  1.38223418e+00, -7.50728794e-02,\n",
       "         4.91772590e-01,  1.68935993e+00, -8.56925784e-01,\n",
       "         8.24201843e-01, -5.68475943e-01,  9.62099762e-01,\n",
       "         6.67502964e-01,  1.46282288e+00, -3.50769791e-01,\n",
       "        -1.07097719e-01, -8.17914808e-01,  2.54128161e-01,\n",
       "         9.00853227e-02,  6.24532075e-01, -1.38318149e+00,\n",
       "         7.06971345e-01, -1.19665169e+00],\n",
       "       [ 1.36678478e+00, -3.83443100e-01, -1.51294952e+00,\n",
       "         4.28508821e-01,  5.55530433e-01,  5.18444922e-01,\n",
       "        -9.36263911e-01, -2.00428418e-01,  8.38764090e-01,\n",
       "         5.45514699e-01, -2.12348761e-03, -4.55911731e-01,\n",
       "        -3.30241109e-01,  7.69364265e-01,  1.26485393e+00,\n",
       "        -3.32025298e-01,  3.30780338e-01, -6.62804569e-01,\n",
       "        -4.13299604e-01, -1.54661686e-01],\n",
       "       [-1.52103864e-02,  4.95479992e-01,  1.08541347e+00,\n",
       "         1.07447342e-01,  1.39489702e+00, -1.07421205e+00,\n",
       "         1.19295854e+00,  1.37407105e+00,  9.88315065e-01,\n",
       "         8.16724854e-01,  6.14243943e-01, -1.12484553e+00,\n",
       "         7.42258785e-01, -8.17969449e-01, -4.03095617e-01,\n",
       "        -3.09353861e-01,  1.41041311e+00, -2.44412448e-01,\n",
       "         9.60431190e-01,  5.92139586e-01],\n",
       "       [ 3.00158539e-01,  1.09981404e+00, -2.13765037e+00,\n",
       "        -1.10838370e+00, -3.24088891e-01,  9.80614521e-01,\n",
       "         4.47098184e-01,  6.79183373e-01, -9.47362361e-01,\n",
       "        -5.72461108e-01,  1.34046603e+00, -3.07215152e-01,\n",
       "         6.57127596e-01,  4.35586060e-01, -1.02632349e-01,\n",
       "         1.20785343e+00, -1.17286330e-01,  1.68583168e+00,\n",
       "         7.37946532e-02, -6.49656011e-01],\n",
       "       [ 1.87988240e-01,  3.49758131e-01,  5.70125823e-01,\n",
       "         4.03952391e-01,  1.30586194e+00, -5.00623433e-01,\n",
       "        -2.31401885e+00, -7.53885717e-02,  1.06057799e+00,\n",
       "         1.09973814e+00, -4.76895552e-02,  9.44017664e-01,\n",
       "         2.24890467e+00, -6.63882725e-01, -7.84502872e-01,\n",
       "        -1.89257914e+00,  2.82377084e+00,  9.09196485e-02,\n",
       "        -9.70718140e-02,  2.67350592e-01],\n",
       "       [-6.02266714e-01,  4.20862847e-01, -5.93515131e-01,\n",
       "        -8.79257046e-01,  2.32585045e+00, -2.39857289e-01,\n",
       "        -7.37466570e-02, -9.52666559e-01,  3.51189439e-02,\n",
       "         7.03959598e-02, -2.81998774e+00, -8.53784628e-01,\n",
       "         2.95484004e-01, -1.65397573e+00,  6.15293638e-01,\n",
       "        -6.38669779e-01,  2.92889040e-01,  1.02287886e+00,\n",
       "        -2.58869486e-01, -2.82155909e-01],\n",
       "       [ 1.13410121e-01, -7.69462842e-01,  1.52279656e-01,\n",
       "        -2.26912217e-01,  1.69539165e+00, -4.79773305e-01,\n",
       "         3.12565921e-01,  1.65339709e-01, -9.72242372e-01,\n",
       "        -5.00430233e-01, -8.47222562e-01,  4.70123837e-01,\n",
       "         1.24067729e+00, -6.22175687e-01,  1.11204504e+00,\n",
       "        -8.37106812e-01,  3.90503204e-01, -9.97064734e-01,\n",
       "        -1.47386152e+00,  2.08678644e-01],\n",
       "       [-9.59566950e-01,  1.19416754e-01, -8.13530046e-01,\n",
       "         6.93534172e-01,  2.58077610e-01,  2.28050137e+00,\n",
       "         1.21904071e+00, -2.17801258e-01, -1.52814190e+00,\n",
       "        -1.31662986e+00,  1.58296319e+00,  4.08834165e-01,\n",
       "        -1.49763059e+00, -1.18950500e+00, -5.09270785e-01,\n",
       "        -2.93454251e-02, -2.49648854e+00, -4.98503394e-01,\n",
       "        -4.91345279e-01,  7.28827390e-01],\n",
       "       [-8.66224046e-01,  2.78333613e-01,  5.94403670e-01,\n",
       "         6.68352560e-01, -5.27064930e-01,  8.36722567e-01,\n",
       "        -6.28289053e-01,  2.00624913e+00,  9.94906996e-01,\n",
       "         7.49532693e-01, -1.53084630e+00, -2.73265606e-02,\n",
       "         2.74744299e-01, -1.31257634e-01, -1.53552490e+00,\n",
       "        -9.01206549e-01,  9.93594634e-01, -6.94975668e-01,\n",
       "        -8.67291633e-01, -4.08711006e-01],\n",
       "       [-2.56026874e-01,  4.27043213e-01, -4.84241202e-01,\n",
       "         3.53544893e-02, -8.51095561e-02,  1.74676265e-01,\n",
       "        -2.10595295e-01,  1.66765050e+00,  9.46129837e-01,\n",
       "         6.48561118e-01, -1.31794816e-01,  1.02080237e+00,\n",
       "        -1.56455940e-01,  1.39682657e+00,  1.42234639e+00,\n",
       "        -3.54425929e-01,  5.68034109e-01, -8.72711265e-01,\n",
       "         1.69230224e-01, -9.27549146e-01],\n",
       "       [-1.27710548e+00,  3.57627401e-01,  1.94717711e-01,\n",
       "         3.26927552e-01,  1.42113595e+00,  1.16786979e+00,\n",
       "        -3.50991387e-01,  1.03542341e+00, -3.83300699e+00,\n",
       "        -2.31893978e+00, -7.63949804e-01,  1.03019713e+00,\n",
       "         2.64067501e+00, -1.78059268e+00, -2.01109842e-01,\n",
       "        -7.18215806e-03, -4.90820075e-01, -3.40752529e-01,\n",
       "        -5.30523004e-01,  1.05072044e+00],\n",
       "       [-5.50668655e-01, -1.73628273e+00,  7.24310523e-01,\n",
       "        -6.35411225e-01,  1.22093571e+00,  1.52022541e+00,\n",
       "         4.78177163e-01,  7.28857710e-01,  7.43404121e-01,\n",
       "         3.25373217e-01, -1.20822289e+00, -2.36367497e+00,\n",
       "        -1.32115442e+00, -1.59619013e-01, -1.32811141e+00,\n",
       "        -4.39350139e-01, -6.34631380e-01, -9.86192898e-01,\n",
       "        -2.26603679e-01,  9.94654970e-02],\n",
       "       [ 3.33485324e-01,  4.37893878e-01,  5.93683724e-01,\n",
       "        -6.58608263e-01,  1.28446763e+00,  1.34767905e+00,\n",
       "         1.00650545e-01,  1.65907739e-01, -1.97083237e+00,\n",
       "        -1.09061685e+00, -7.38577860e-01, -8.86814929e-01,\n",
       "         2.01938766e+00, -1.34166935e-01,  9.64136355e-01,\n",
       "        -6.34676878e-01,  3.44502498e-01,  1.81618258e+00,\n",
       "         9.31343294e-01, -4.23246895e-01],\n",
       "       [-9.50504135e-01, -1.67313471e+00,  6.23642064e-01,\n",
       "        -1.60725068e+00, -3.90953906e-01,  7.18778282e-01,\n",
       "         7.12677699e-02, -9.27379906e-01,  9.65662146e-01,\n",
       "         7.51478004e-01, -2.60160326e-01,  4.04802784e-02,\n",
       "         4.22623616e-01,  6.38754260e-01, -2.07926519e+00,\n",
       "         1.04542788e+00,  1.10508054e+00,  2.72283709e-01,\n",
       "         1.27299197e+00, -9.69704999e-01],\n",
       "       [-6.23191880e-01,  2.67680736e-01, -6.25758271e-01,\n",
       "         5.89524220e-03, -3.24361530e-01, -1.05211213e+00,\n",
       "        -6.24412416e-01,  1.16373847e+00, -1.41648950e+00,\n",
       "        -7.85815341e-01,  1.43211786e+00, -5.51172514e-01,\n",
       "         1.43863865e+00,  1.46111365e+00,  9.03825135e-01,\n",
       "         3.66824496e-01,  2.36101965e-01,  1.38129237e+00,\n",
       "         7.87122976e-01,  1.67202286e-01],\n",
       "       [ 1.98595607e+00, -1.50173805e+00,  3.97786954e-01,\n",
       "         9.67146576e-03, -2.63397621e+00,  6.51606319e-01,\n",
       "        -5.20336716e-01, -1.43120910e+00,  3.64054738e-01,\n",
       "         1.55628446e-01,  8.81674069e-02, -4.79460284e-01,\n",
       "        -6.71124377e-01, -9.40250448e-02, -1.02695678e+00,\n",
       "        -8.77187836e-01, -3.32562725e-01,  3.57328175e-02,\n",
       "        -4.44591927e-02, -5.63847935e-02],\n",
       "       [ 1.59015894e+00,  9.88573514e-01,  9.19769486e-01,\n",
       "        -6.26096635e-01, -8.92800681e-01, -7.56239997e-01,\n",
       "         6.91577413e-02,  2.33453439e+00, -8.41105404e-01,\n",
       "        -7.27028848e-01,  1.19086324e+00, -1.38788278e+00,\n",
       "        -8.39543904e-01,  9.17962776e-01, -4.08758442e-01,\n",
       "         4.10604979e-01, -1.38783509e+00, -1.01511759e+00,\n",
       "         9.80239275e-01, -1.22622733e+00]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9249707 , 0.03110778, 0.967145  , 0.25543132, 0.05689516,\n",
       "       0.8208202 , 0.8024059 , 0.9799483 , 0.8527327 , 0.26427805,\n",
       "       0.95896983, 0.50783724, 0.95464176, 0.5780617 , 0.9454438 ,\n",
       "       0.07998231, 0.7849171 , 0.72404534, 0.92745286, 0.04240661,\n",
       "       0.9402491 , 0.8283368 , 0.9124435 , 0.01633013, 0.01788557],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is `pyfunc` flavor anyway? https://www.mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlmodel-configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also infer your models as a service or as Spark UDF. Let's switch to a more realistic example for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = data[\"frame\"]\n",
    "target = pdf.pop(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_train, pdf_test, target_train, target_test = train_test_split(pdf, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'Iris with sklearn' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Iris with sklearn\")\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"The run I need\"):\n",
    "    pdf_train.to_pickle(\"dataset_train.pickle\")\n",
    "    mlflow.log_artifact(\"dataset_train.pickle\")\n",
    "    pipeline.fit(pdf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.search_runs(experiment_ids=client.get_experiment_by_name(\"Iris with sklearn\").experiment_id,\n",
    "                         filter_string=\"tags.`mlflow.runName` = 'The run I need'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/users/vova-cmc/ozon-masters-bigdata/lectures/lect8%20-%20MlFlow/mlruns/3/be0f6a0696dc4ecab735acfd25c24790/artifacts'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[0].info.artifact_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "skmodel = mlflow.pyfunc.load_model(f\"{run[0].info.artifact_uri}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: model\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: be0f6a0696dc4ecab735acfd25c24790"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmodel.predict(pdf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it with Spark UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "SPARK_HOME = \"/usr/hdp/current/spark2-client\"\n",
    "PYSPARK_PYTHON = \"/opt/conda/envs/dsenv/bin/python\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]= PYSPARK_PYTHON\n",
    "os.environ[\"SPARK_HOME\"] = SPARK_HOME\n",
    "\n",
    "PYSPARK_HOME = os.path.join(SPARK_HOME, \"python/lib\")\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"py4j-0.10.7-src.zip\"))\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"pyspark.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"4g\")\n",
    "conf.set(\"spark.driver.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"MLflow model inference with Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://edge1.ru-central1.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MLflow model inference with Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7efdb0eb0b10>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_udf = mlflow.pyfunc.spark_udf(spark, model_uri=f\"{run[0].info.artifact_uri}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function mlflow.pyfunc.spark_udf.<locals>.predict(*args)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(pdf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal length (cm): double (nullable = true)\n",
      " |-- sepal width (cm): double (nullable = true)\n",
      " |-- petal length (cm): double (nullable = true)\n",
      " |-- petal width (cm): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+----------+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|prediction|\n",
      "+-----------------+----------------+-----------------+----------------+----------+\n",
      "|              5.8|             2.7|              4.1|             1.0|       1.0|\n",
      "|              5.4|             3.9|              1.3|             0.4|       0.0|\n",
      "|              7.6|             3.0|              6.6|             2.1|       2.0|\n",
      "|              5.8|             2.7|              5.1|             1.9|       2.0|\n",
      "|              7.2|             3.0|              5.8|             1.6|       2.0|\n",
      "|              4.8|             3.4|              1.6|             0.2|       0.0|\n",
      "|              6.1|             3.0|              4.9|             1.8|       2.0|\n",
      "|              6.5|             3.0|              5.8|             2.2|       2.0|\n",
      "|              5.5|             4.2|              1.4|             0.2|       0.0|\n",
      "|              4.9|             3.0|              1.4|             0.2|       0.0|\n",
      "+-----------------+----------------+-----------------+----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.withColumn(\"prediction\", spark_udf(*spark_df.schema.fieldNames())).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow projects\n",
    "### An MLflow Project is a format for packaging data science code in a reusable and reproducible way, based primarily on conventions. In addition, the Projects component includes an API and command-line tools for running projects, making it possible to chain together projects into workflows.\n",
    "\n",
    "https://www.mlflow.org/docs/latest/projects.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
